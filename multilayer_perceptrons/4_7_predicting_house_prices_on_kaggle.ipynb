{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url, folder, sha1_hash=None):\n",
    "    \"\"\"Download a file to folder and return the local filepath.\"\"\"\n",
    "\n",
    "def extract(filename, folder):\n",
    "    \"\"\"Extract a zip/tar file into folder.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KaggleHouse(d2l.DataModule):\n",
    "    def __init__(self, batch_size, train=None, val=None):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        if self.train is None:\n",
    "            self.raw_train = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_train.csv', self.root,\n",
    "                sha1_hash='585e9cc93e70b39160e7921475f9bcd7d31219ce'))\n",
    "            self.raw_val = pd.read_csv(d2l.download(\n",
    "                d2l.DATA_URL + 'kaggle_house_pred_test.csv', self.root,\n",
    "                sha1_hash='fa19780a7b011d9b009e8bff8e99922a8ee2eb90'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../data/kaggle_house_pred_train.csv from http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv...\n",
      "Downloading ../data/kaggle_house_pred_test.csv from http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv...\n",
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "data = KaggleHouse(batch_size=64)\n",
    "print(data.raw_train.shape)\n",
    "print(data.raw_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n"
     ]
    }
   ],
   "source": [
    "print(data.raw_train.iloc[:4, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def preprocess(self):\n",
    "    # Remove the ID and label columns\n",
    "    label = 'SalePrice'\n",
    "    features = pd.concat(\n",
    "        (self.raw_train.drop(columns=['Id', label]),\n",
    "         self.raw_val.drop(columns=['Id'])))\n",
    "    # Standardize numerical columns\n",
    "    numeric_features = features.dtypes[features.dtypes!='object'].index\n",
    "    features[numeric_features] = features[numeric_features].apply(\n",
    "        lambda x: (x - x.mean()) / (x.std()))\n",
    "    # Replace NAN numerical features by 0\n",
    "    features[numeric_features] = features[numeric_features].fillna(0)\n",
    "    # Replace discrete features by one-hot encoding\n",
    "    features = pd.get_dummies(features, dummy_na=True)\n",
    "    # Save preprocessed features\n",
    "    self.train = features[:self.raw_train.shape[0]].copy()\n",
    "    self.train[label] = self.raw_train[label]\n",
    "    self.val = features[self.raw_train.shape[0]:].copy()\n",
    "\n",
    "''' \n",
    "这段代码定义了一个名为`preprocess`的函数，用于预处理Kaggle房价预测任务的数据。该函数主要执行以下操作：\n",
    "\n",
    "1. 删除ID和标签列：从原始训练集和验证集中删除ID列和'SalePrice'标签列，将剩余的特征组合在一起。\n",
    "\n",
    "2. 标准化数值特征：找到数值型特征（即不是对象类型的特征），并对它们进行标准化。标准化是将每个特征减去其均值并除以其标准差，从而使特征具有零均值和单位方差。\n",
    "\n",
    "3. 用0替换缺失的数值特征：将数值特征中的NaN值替换为0。\n",
    "\n",
    "4. 用one-hot编码替换离散特征：将离散特征转换为one-hot编码表示。`pd.get_dummies`函数可以自动找到离散特征并创建one-hot编码。`dummy_na=True`表示对于具有NaN值的特征，也创建一个表示缺失值的新列。\n",
    "\n",
    "5. 保存预处理后的特征：将预处理后的特征分为训练集和验证集，并将'SalePrice'标签列添加回训练集。\n",
    "\n",
    "这个预处理函数的目的是为了在训练模型之前清洗和准备数据。通过标准化数值特征、处理缺失值和将离散特征转换为one-hot编码，我们可以确保模型接收到适当格式的输入数据。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 331)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.preprocess()\n",
    "data.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(KaggleHouse)\n",
    "def get_dataloader(self, train):\n",
    "    label = 'SalePrice'\n",
    "    data = self.train if train else self.val\n",
    "    if label not in data: return\n",
    "    get_tensor = lambda x: torch.tensor(x.values.astype(float),\n",
    "                                      dtype=torch.float32)\n",
    "    # Logarithm of prices\n",
    "    tensors = (get_tensor(data.drop(columns=[label])),  # X\n",
    "               torch.log(get_tensor(data[label])).reshape((-1, 1)))  # Y\n",
    "    return self.get_tensorloader(tensors, train)\n",
    "\n",
    "  ''' \n",
    "  这段代码定义了一个名为`get_dataloader`的函数，用于为Kaggle房价预测任务的数据生成数据加载器。该函数根据输入参数`train`的值，为训练集或验证集创建一个PyTorch数据加载器。\n",
    "\n",
    "1. 首先，根据`train`参数选择要处理的数据集（训练集或验证集）。如果数据集中没有标签列（'SalePrice'），则返回None。\n",
    "\n",
    "2. 定义一个名为`get_tensor`的辅助函数，用于将Pandas DataFrame数据转换为PyTorch张量。这个函数接受一个DataFrame对象，将其值转换为浮点数，并创建一个相应的PyTorch张量。\n",
    "\n",
    "3. 使用`get_tensor`函数创建输入特征（X）和目标变量（Y）的张量。对于目标变量（房价），我们对其值取对数，以便在训练过程中更好地处理不同数量级的房价。将房价张量Y调整为列向量。\n",
    "\n",
    "4. 调用`self.get_tensorloader`函数，为给定的输入特征和目标变量张量创建一个PyTorch数据加载器。这个加载器将用于在训练和评估模型时批量加载数据。\n",
    "\n",
    "这个`get_dataloader`函数的目的是简化从预处理过的数据集中获取数据的过程。通过为训练集和验证集创建数据加载器，我们可以轻松地在训练和评估模型时批量加载数据。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
