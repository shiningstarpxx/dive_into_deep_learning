{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=3, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, num_convs, num_channels):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layer = []\n",
    "        for i in range(num_convs):\n",
    "            layer.append(conv_block(num_channels))\n",
    "        self.net = nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for blk in self.net:\n",
    "            Y = blk(X)\n",
    "            # Concatenate input and output of each block along the channels\n",
    "            X = torch.cat((X, Y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data2/miniconda3/envs/d2l-pytorch/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = DenseBlock(2, 10)\n",
    "X = torch.randn(4, 3, 8, 8)\n",
    "Y = blk(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.LazyConv2d(num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(10)\n",
    "blk(Y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(d2l.Classifier):\n",
    "    def b1(self):\n",
    "        return nn.Sequential(\n",
    "            nn.LazyConv2d(64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(DenseNet)\n",
    "def __init__(self, num_channels=64, growth_rate=32, arch=(4, 4, 4, 4),\n",
    "             lr=0.1, num_classes=10):\n",
    "    super(DenseNet, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    self.net = nn.Sequential(self.b1())\n",
    "    for i, num_convs in enumerate(arch):\n",
    "        self.net.add_module(f'dense_blk{i+1}', DenseBlock(num_convs,\n",
    "                                                          growth_rate))\n",
    "        # The number of output channels in the previous dense block\n",
    "        num_channels += num_convs * growth_rate\n",
    "        # A transition layer that halves the number of channels is added\n",
    "        # between the dense blocks\n",
    "        if i != len(arch) - 1:\n",
    "            num_channels //= 2\n",
    "            self.net.add_module(f'tran_blk{i+1}', transition_block(\n",
    "                num_channels))\n",
    "    self.net.add_module('last', nn.Sequential(\n",
    "        nn.LazyBatchNorm2d(), nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten(),\n",
    "        nn.LazyLinear(num_classes)))\n",
    "    self.net.apply(d2l.init_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GET was unable to find an engine to execute this computation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/home/michaelpei/code/dive_into_deep_learning/8_modern_convolutional_neural_networks/8_7_densely_connected_networks_DenseNet.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B9.135.143.180/data/home/michaelpei/code/dive_into_deep_learning/8_modern_convolutional_neural_networks/8_7_densely_connected_networks_DenseNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m trainer \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mTrainer(max_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, num_gpus\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B9.135.143.180/data/home/michaelpei/code/dive_into_deep_learning/8_modern_convolutional_neural_networks/8_7_densely_connected_networks_DenseNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m d2l\u001b[39m.\u001b[39mFashionMNIST(batch_size\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m, resize\u001b[39m=\u001b[39m(\u001b[39m96\u001b[39m, \u001b[39m96\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B9.135.143.180/data/home/michaelpei/code/dive_into_deep_learning/8_modern_convolutional_neural_networks/8_7_densely_connected_networks_DenseNet.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, data)\n",
      "File \u001b[0;32m/data2/miniconda3/envs/d2l-pytorch/lib/python3.8/site-packages/d2l/torch.py:285\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_batch_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_epochs):\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_epoch()\n",
      "File \u001b[0;32m/data2/miniconda3/envs/d2l-pytorch/lib/python3.8/site-packages/d2l/torch.py:301\u001b[0m, in \u001b[0;36mTrainer.fit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m    300\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 301\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_clip_val \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# To be discussed later\u001b[39;00m\n\u001b[1;32m    303\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclip_gradients(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgradient_clip_val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n",
      "File \u001b[0;32m/data2/miniconda3/envs/d2l-pytorch/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m/data2/miniconda3/envs/d2l-pytorch/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GET was unable to find an engine to execute this computation"
     ]
    }
   ],
   "source": [
    "model = DenseNet(lr=0.01)\n",
    "trainer = d2l.Trainer(max_epochs=10, num_gpus=1)\n",
    "data = d2l.FashionMNIST(batch_size=128, resize=(96, 96))\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n1. 为什么在过渡层中使用平均池化而不是最大池化？\\n   \\n   平均池化在过渡层中的使用是为了减小特征图的尺寸，同时保留更多的空间信息。相比之下，最大池化只保留最显著的特征，可能会导致一些空间信息的丢失。此外，平均池化对输入的响应更平滑，有助于降低过拟合的风险。\\n\\n2. 在DenseNet论文中提到的优点之一是其模型参数比ResNet的参数少。为什么会这样？\\n\\n   这是因为DenseNet的设计允许特征重用，从而减少了每个层所需的参数数量。在DenseNet中，每个层都直接连接到其之前的所有层，这意味着网络可以利用之前层的特征而无需重新计算。因此，DenseNet可以使用较少的参数来实现与ResNet相当的性能。\\n\\n3. DenseNet被批评的一个问题是其高内存消耗。这真的是这样吗？尝试将输入形状更改为(224, 224)以经验性地比较实际GPU内存消耗。\\n\\n   是的，DenseNet的内存消耗相对较高，因为它在每个层之间保持密集连接，这导致了较大的特征图。当输入尺寸增加时，内存消耗可能会变得更明显。为了经验性地比较内存消耗，您可以尝试使用不同的输入尺寸并监控GPU内存使用情况。\\n\\n4. 您能想到一种替代方法来减少内存消耗吗？您需要如何更改框架？\\n\\n   减少内存消耗的一种方法是使用更小的增长率（k值），这将导致每个层生成较少的特征图。但是，这可能会影响模型的性能。另一种方法是使用稀疏连接而不是密集连接。这可以减少特征图的数量，从而降低内存消耗。为了实现这种方法，您需要更改DenseNet的框架，使每个层只连接到部分先前层，而不是所有先前层。\\n\\n5. 实现DenseNet论文（Huang等人，2017）表1中介绍的各种DenseNet版本。\\n\\n   要实现DenseNet论文中的不同版本，您需要根据表1中的建议调整网络的深度、增长率和过渡层。具体来说，您可以更改DenseNet类的参数，例如设置不同的层数（L）、增长率（k）和压缩率（θ）。\\n\\n6. 通过应用DenseNet思想设计一个基于MLP的模型。将其应用于第5.7节中的房价预测任务。\\n\\n   要将DenseNet应用于MLP，您可以创建一个具有密集连接的多层感知器。在每个隐藏层之间，您可以添加一个连接层，将当前层的输出与之前所有层的输出连接起来。在实现这样的模型时，您需要确保输入和输出尺寸匹配房价预测任务的要求。然后，您可以使用类似于第5.7节中的方法来训练和评估模型。\\n   '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "1. 为什么在过渡层中使用平均池化而不是最大池化？\n",
    "   \n",
    "   平均池化在过渡层中的使用是为了减小特征图的尺寸，同时保留更多的空间信息。相比之下，最大池化只保留最显著的特征，可能会导致一些空间信息的丢失。此外，平均池化对输入的响应更平滑，有助于降低过拟合的风险。\n",
    "\n",
    "2. 在DenseNet论文中提到的优点之一是其模型参数比ResNet的参数少。为什么会这样？\n",
    "\n",
    "   这是因为DenseNet的设计允许特征重用，从而减少了每个层所需的参数数量。在DenseNet中，每个层都直接连接到其之前的所有层，这意味着网络可以利用之前层的特征而无需重新计算。因此，DenseNet可以使用较少的参数来实现与ResNet相当的性能。\n",
    "\n",
    "3. DenseNet被批评的一个问题是其高内存消耗。这真的是这样吗？尝试将输入形状更改为(224, 224)以经验性地比较实际GPU内存消耗。\n",
    "\n",
    "   是的，DenseNet的内存消耗相对较高，因为它在每个层之间保持密集连接，这导致了较大的特征图。当输入尺寸增加时，内存消耗可能会变得更明显。为了经验性地比较内存消耗，您可以尝试使用不同的输入尺寸并监控GPU内存使用情况。\n",
    "\n",
    "4. 您能想到一种替代方法来减少内存消耗吗？您需要如何更改框架？\n",
    "\n",
    "   减少内存消耗的一种方法是使用更小的增长率（k值），这将导致每个层生成较少的特征图。但是，这可能会影响模型的性能。另一种方法是使用稀疏连接而不是密集连接。这可以减少特征图的数量，从而降低内存消耗。为了实现这种方法，您需要更改DenseNet的框架，使每个层只连接到部分先前层，而不是所有先前层。\n",
    "\n",
    "5. 实现DenseNet论文（Huang等人，2017）表1中介绍的各种DenseNet版本。\n",
    "\n",
    "   要实现DenseNet论文中的不同版本，您需要根据表1中的建议调整网络的深度、增长率和过渡层。具体来说，您可以更改DenseNet类的参数，例如设置不同的层数（L）、增长率（k）和压缩率（θ）。\n",
    "\n",
    "6. 通过应用DenseNet思想设计一个基于MLP的模型。将其应用于第5.7节中的房价预测任务。\n",
    "\n",
    "   要将DenseNet应用于MLP，您可以创建一个具有密集连接的多层感知器。在每个隐藏层之间，您可以添加一个连接层，将当前层的输出与之前所有层的输出连接起来。在实现这样的模型时，您需要确保输入和输出尺寸匹配房价预测任务的要求。然后，您可以使用类似于第5.7节中的方法来训练和评估模型。\n",
    "   ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
